{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_lg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOpeVgMSZdOg",
        "outputId": "50b6833d-b2a3-46d3-c4ef-51bc6be47765"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-04-17 00:10:28.952555: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-lg==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.5.0/en_core_web_lg-3.5.0-py3-none-any.whl (587.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.9/dist-packages (from en-core-web-lg==3.5.0) (3.5.1)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (67.6.1)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (23.0)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.10.7)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.1.2)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.5.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import spacy\n",
        "import string\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from collections import Counter\n",
        "import statistics\n",
        "from statistics import mode\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_lg\")"
      ],
      "metadata": {
        "id": "tIy86FL_ZsWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/data\"\n",
        "dir_list = os.listdir(path)\n",
        "os.chdir(\"/content/data\")\n",
        "\n",
        "universal_new_lines = '\\n' + '\\r' + '\\r\\n' + '\\v' + '\\x0b' + '\\f' + '\\x0c' + '\\x1c' + '\\x1d' + '\\x1e' + '\\x85' + '\\u2028' + '\\u2029' \n",
        "pun = string.punctuation + '\\t' + '—' + '‘’' + universal_new_lines\n",
        "label_list = ['PERSON', 'ORG', 'GPE']\n",
        "fields = ['FILE', 'PERSON', 'ORG', 'GPE', 'YEAR', 'AGENCY']\n",
        "processed_data = []"
      ],
      "metadata": {
        "id": "avV7fEDFaZAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_processing(data):\n",
        "  # removing punctuations and new lines and tabs\n",
        "  for sym in pun:\n",
        "    cnt = data.count(sym)\n",
        "    data = data.replace(sym, '', cnt)\n",
        "\n",
        "  # lower the data\n",
        "  data = data.lower()\n",
        "  doc = nlp(data)\n",
        "\n",
        "  token_classification = {'FILE':'NA','PERSON':'NA', 'ORG':'NA', 'GPE':'NA', 'YEAR':'NA', 'AGENCY':'NA'}\n",
        "\n",
        "  year = []\n",
        "  for token in doc:\n",
        "    if token.pos_ == 'NUM' and token.shape_ == 'dddd':\n",
        "      year.append(token.text)\n",
        "\n",
        "  if len(year) == 0:\n",
        "    token_classification['YEAR'] = 'NA'\n",
        "  else:\n",
        "    token_classification['YEAR'] = mode(year)\n",
        "\n",
        "  # fetching entities and keywords\n",
        "  person = []\n",
        "  org = []\n",
        "  gpe = []\n",
        "  for ent in doc.ents:\n",
        "    if ent.label_ in label_list:\n",
        "      if ent.label_ == 'PERSON':\n",
        "        person.append(ent.text)\n",
        "      elif ent.label_ == 'ORG':\n",
        "        org.append(ent.text)\n",
        "      elif ent.label_ == 'GPE':\n",
        "        gpe.append(ent.text)\n",
        "\n",
        "  if len(person) == 0:\n",
        "    token_classification['PERSON'] = 'NA'\n",
        "  else:\n",
        "    token_classification['PERSON'] = mode(person)\n",
        "\n",
        "  if len(org) == 0:\n",
        "    token_classification['ORG'] = 'NA'\n",
        "  else:\n",
        "    token_classification['ORG'] = mode(org)\n",
        "\n",
        "  if len(gpe) == 0:\n",
        "    token_classification['GPE'] = 'NA'\n",
        "  else:\n",
        "    token_classification['GPE'] = mode(gpe)\n",
        "\n",
        "  return token_classification"
      ],
      "metadata": {
        "id": "xg0pPKFTaaTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for fname in dir_list:\n",
        "\n",
        "  file = open(fname)\n",
        "  c = 0\n",
        "  content_list = file.readlines()\n",
        "  while '\\n' in content_list:\n",
        "    content_list.remove('\\n')\n",
        "  for content in content_list:\n",
        "    c = c + 1\n",
        "    token_classification = data_processing(content)\n",
        "    token_classification['FILE'] = fname.replace(\"_docs.txt\", str(c))\n",
        "    token_classification['AGENCY'] = fname.replace(\"_docs.txt\", '')\n",
        "    processed_data.append(token_classification)\n",
        "# print(processed_data)\n",
        "\n",
        "with open(\"/content/ProcessedData.csv\", 'w') as csvfile:\n",
        "  writer = csv.DictWriter(csvfile, fieldnames = fields)\n",
        "  writer.writeheader()\n",
        "  writer.writerows(processed_data)"
      ],
      "metadata": {
        "id": "6BLo93sSakbv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}